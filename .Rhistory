#wlaczene bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "C:\\PW\\PJN\\"
setwd(workDir)
#definicja katalogÃ³w projektu
inputDir <- ".\\data"
outputDir <- ".\\results"
scriptsDir <- ".\\scripts"
#utworzenie katalogu wyjsciowego
dir.create(outputDir, showWarnings = FALSE)
#utworzenie korpusu dokumentow
corpusDir <- paste(inputDir, "\\", "Literatura - streszczenia - oryginał", sep = "")
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
#wstepne przetwarzanie
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
stoplistFile <- paste(
inputDir,
"\\",
"stopwords_pl.txt",
sep = ""
)
stoplist <- readLines(
stoplistFile,
encoding = "UTF-8"
)
corpus <- tm_map(corpus, removeWords, stoplist)
corpus <- tm_map(corpus, stripWhitespace)
remove_char <- content_transformer(
function(x, pattern, replacement)
gsub(pattern, replacement, x)
)
#usuniecie "m dash" i 3/4 z tekstow
corpus <- tm_map(corpus, remove_char, intToUtf8(8722), "")
corpus <- tm_map(corpus, remove_char, intToUtf8(190), "")
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
#utworzenie korpusu dokumentow
corpusDir <- paste(inputDir, "\\", "Literatura - streszczenia - oryginał", sep = "")
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
#wlaczene bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "C:\\PW\\PJN\\"
setwd(workDir)
#definicja katalogÃ³w projektu
inputDir <- ".\\data"
outputDir <- ".\\results"
scriptsDir <- ".\\scripts"
#utworzenie katalogu wyjsciowego
dir.create(outputDir, showWarnings = FALSE)
#utworzenie korpusu dokumentow
corpusDir <- paste(inputDir, "\\", "Literatura - streszczenia - oryginal", sep = "")
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
#wstepne przetwarzanie
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
stoplistFile <- paste(
inputDir,
"\\",
"stopwords_pl.txt",
sep = ""
)
stoplist <- readLines(
stoplistFile,
encoding = "UTF-8"
)
corpus <- tm_map(corpus, removeWords, stoplist)
corpus <- tm_map(corpus, stripWhitespace)
remove_char <- content_transformer(
function(x, pattern, replacement)
gsub(pattern, replacement, x)
)
#usuniecie "m dash" i 3/4 z tekstow
corpus <- tm_map(corpus, remove_char, intToUtf8(8722), "")
corpus <- tm_map(corpus, remove_char, intToUtf8(190), "")
View(corpus)
View(corpus)
View(corpus)
install.packages("hunspell")
